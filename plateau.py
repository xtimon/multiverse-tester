"""
–ü–û–õ–ù–´–ô –ê–ù–ê–õ–ò–ó –ü–õ–ê–¢–û –ü–†–ò–ì–û–î–ù–û–°–¢–ò –í–°–ï–õ–ï–ù–ù–´–•
===========================================
–≠—Ç–∞–ø—ã:
1. –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ multiverse-tester
2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π Œ±
3. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –º–æ–¥–µ–ª–∏
4. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∞–Ω–∞–ª–∏–∑
5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
"""

import json
import os
from datetime import datetime
from typing import Any

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from scipy.integrate import quad
from scipy.optimize import fsolve, minimize_scalar

# ============================================================================
# 1. –ò–ú–ü–û–†–¢ –ë–ò–ë–õ–ò–û–¢–ï–ö–ò MULTIVERSE-TESTER
# ============================================================================

try:
    from multiverse_tester import UniverseAnalyzer, UniverseParameters

    print("‚úÖ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ multiverse-tester —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞")
except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
    print("   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫—É: pip install multiverse-tester")
    raise SystemExit(1) from e

# ============================================================================
# 2. –ö–û–ù–°–¢–ê–ù–¢–´ –ò –ü–ê–†–ê–ú–ï–¢–†–´
# ============================================================================

# –ß–∏—Å–ª–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
GRID_POINTS_FINE = 10_000
GRID_POINTS_PLOT = 1_000
PROGRESS_BAR_LENGTH = 30
PEAK_SEARCH_BOUNDS = (0.006, 0.008)

# –ë–∞–∑–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –Ω–∞—à–µ–π –í—Å–µ–ª–µ–Ω–Ω–æ–π
OUR_UNIVERSE: dict[str, Any] = {
    "name": "–ù–∞—à–∞ –í—Å–µ–ª–µ–Ω–Ω–∞—è",
    "alpha": 1 / 137.036,  # 0.007297
    "m_p": 1.6726219e-27,
    "m_e": 9.1093837e-31,
    "G": 6.6743e-11,
    "c": 299792458,
    "hbar": 1.0545718e-34,
    "epsilon_0": 8.8541878128e-12,
    "k_B": 1.380649e-23,
    "H_0": 67.4,
    "Lambda": 1e-52,
}

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
STUDY_PARAMS: dict[str, Any] = {
    "alpha_range": (0.005, 0.012),
    "alpha_points": 20,
    "fixed_params": {
        "m_p": OUR_UNIVERSE["m_p"],
        "m_e": OUR_UNIVERSE["m_e"],
        "G": OUR_UNIVERSE["G"],
        "c": OUR_UNIVERSE["c"],
        "hbar": OUR_UNIVERSE["hbar"],
        "epsilon_0": OUR_UNIVERSE["epsilon_0"],
        "k_B": OUR_UNIVERSE["k_B"],
        "H_0": OUR_UNIVERSE["H_0"],
        "Lambda": OUR_UNIVERSE["Lambda"],
    },
}

THRESHOLDS = {
    "optimal": 0.875,
    "marginal": 0.84,
    "hostile": 0.80,
}

ZONE_COLORS = {"optimal": "green", "marginal": "orange", "hostile": "red"}
OUTPUT_DIR = "reports"

# ============================================================================
# 3. –ì–ï–ù–ï–†–ê–¶–ò–Ø –î–ê–ù–ù–´–• –° –ü–û–ú–û–©–¨–Æ –ë–ò–ë–õ–ò–û–¢–ï–ö–ò
# ============================================================================


def _analyze_single_universe(alpha: float) -> tuple[float, str, Any]:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–¥–Ω—É –≤—Å–µ–ª–µ–Ω–Ω—É—é —Å –∑–∞–¥–∞–Ω–Ω—ã–º Œ±."""
    universe = UniverseParameters(
        name=f"Œ±={alpha:.4f}",
        alpha=alpha,
        **STUDY_PARAMS["fixed_params"],
    )
    analyzer = UniverseAnalyzer(universe)
    index, score, metrics = analyzer.calculate_habitability_index()
    return score, index.name, metrics


def _print_progress(i: int, total: int, alpha: float, score: float) -> None:
    """–í—ã–≤–æ–¥–∏—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –≤ –∫–æ–Ω—Å–æ–ª—å."""
    progress = (i + 1) / total * 100
    filled = int(PROGRESS_BAR_LENGTH * (i + 1) // total)
    bar = "‚ñà" * filled + "‚ñë" * (PROGRESS_BAR_LENGTH - filled)
    print(f"\r   [{bar}] {progress:.1f}% | Œ±={alpha:.4f}, H={score:.4f}", end="")


def generate_alpha_data() -> dict[str, Any]:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ, –≤–∞—Ä—å–∏—Ä—É—è Œ± –ø—Ä–∏ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö.

    Returns:
    --------
    dict : {'alpha': array, 'H': array, 'detailed': list of dicts}
    """
    print("\n" + "=" * 70)
    print("üî¨ –ì–ï–ù–ï–†–ê–¶–ò–Ø –î–ê–ù–ù–´–• –° –ü–û–ú–û–©–¨–Æ MULTIVERSE-TESTER")
    print("=" * 70)

    alpha_min, alpha_max = STUDY_PARAMS["alpha_range"]
    n_points = STUDY_PARAMS["alpha_points"]
    alpha_values = np.linspace(alpha_min, alpha_max, n_points)

    results: dict[str, Any] = {"alpha": [], "H": [], "detailed": []}

    print(f"\nüìä –ò—Å—Å–ª–µ–¥—É–µ–º {n_points} –∑–Ω–∞—á–µ–Ω–∏–π Œ± –æ—Ç {alpha_values[0]:.4f} –¥–æ {alpha_values[-1]:.4f}")
    print("-" * 60)

    for i, alpha in enumerate(alpha_values):
        score, category, metrics = _analyze_single_universe(alpha)
        results["alpha"].append(alpha)
        results["H"].append(score)
        results["detailed"].append({
            "alpha": alpha,
            "score": score,
            "category": category,
            "metrics": metrics,
        })
        _print_progress(i, n_points, alpha, score)

    print("\n" + "-" * 60)
    print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(results['alpha'])} —Ç–æ—á–µ–∫ –¥–∞–Ω–Ω—ã—Ö")

    results["alpha"] = np.array(results["alpha"])
    results["H"] = np.array(results["H"])
    return results

# ============================================================================
# 4. –ü–û–°–¢–†–û–ï–ù–ò–ï –ú–ê–¢–ï–ú–ê–¢–ò–ß–ï–°–ö–û–ô –ú–û–î–ï–õ–ò
# ============================================================================


def _compute_r_squared(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """–í—ã—á–∏—Å–ª—è–µ—Ç –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∞—Ü–∏–∏ R¬≤."""
    ss_res = np.sum((y_true - y_pred) ** 2)
    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)
    return 1 - (ss_res / ss_tot)


def _format_polynomial_expression(coeffs: np.ndarray) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –ø–æ–ª–∏–Ω–æ–º–∞ –≤ —á–∏—Ç–∞–µ–º–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ (–¥–ª—è —Å—Ç–µ–ø–µ–Ω–∏ 3)."""
    if len(coeffs) == 4:  # cubic
        return f"H(Œ±) = {coeffs[0]:.2f}¬∑Œ±¬≥ + {coeffs[1]:.2f}¬∑Œ±¬≤ + {coeffs[2]:.2f}¬∑Œ± + {coeffs[3]:.2f}"
    terms = []
    for i, c in enumerate(coeffs):
        power = len(coeffs) - 1 - i
        symbol = "Œ±" if power == 1 else f"Œ±^{power}" if power > 1 else ""
        terms.append(f"{c:.2f}¬∑{symbol}" if symbol else f"{c:.2f}")
    return "H(Œ±) = " + " + ".join(terms)


def fit_polynomial(alpha_data: np.ndarray, H_data: np.ndarray, degree: int = 3) -> dict[str, Any]:
    """
    –ê–ø–ø—Ä–æ–∫—Å–∏–º–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ–ª–∏–Ω–æ–º–æ–º –∑–∞–¥–∞–Ω–Ω–æ–π —Å—Ç–µ–ø–µ–Ω–∏.

    Returns:
    --------
    dict : –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏ (coeffs, poly, degree, r_squared, expression)
    """
    print("\n" + "=" * 70)
    print("üìê –ü–û–°–¢–†–û–ï–ù–ò–ï –ú–ê–¢–ï–ú–ê–¢–ò–ß–ï–°–ö–û–ô –ú–û–î–ï–õ–ò")
    print("=" * 70)

    coeffs = np.polyfit(alpha_data, H_data, degree)
    poly = np.poly1d(coeffs)
    H_pred = poly(alpha_data)
    r_squared = _compute_r_squared(H_data, H_pred)

    model = {
        "coeffs": coeffs,
        "poly": poly,
        "degree": degree,
        "r_squared": r_squared,
        "expression": _format_polynomial_expression(coeffs),
    }

    print(f"\nüìà –ú–æ–¥–µ–ª—å (—Å—Ç–µ–ø–µ–Ω—å {degree}):")
    print(f"   {model['expression']}")
    print(f"   R¬≤ = {r_squared:.6f} (–∫–∞—á–µ—Å—Ç–≤–æ –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏–∏)")

    return model


def _find_boundary(
    poly: np.poly1d,
    threshold: float,
    start: float,
    direction: str,
) -> float | None:
    """–ù–∞—Ö–æ–¥–∏—Ç –≥—Ä–∞–Ω–∏—Ü—É –∑–æ–Ω—ã –ø–æ –ø–æ—Ä–æ–≥—É –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç–∏."""
    alpha_min, alpha_max = STUDY_PARAMS["alpha_range"]
    test = np.linspace(alpha_min, alpha_max, GRID_POINTS_FINE)

    if direction == "right":
        mask = test >= start
        test = test[mask]
        for a in test:
            if poly(a) < threshold:
                return float(a)
    else:
        mask = test <= start
        test = test[mask]
        for a in reversed(test):
            if poly(a) < threshold:
                return float(a)
    return None


def _compute_derivatives(poly: np.poly1d) -> tuple[np.ndarray, np.ndarray, np.ndarray]:
    """–í—ã—á–∏—Å–ª—è–µ—Ç Œ±, dH/dŒ± –∏ d¬≤H/dŒ±¬≤ –Ω–∞ –ø–ª–æ—Ç–Ω–æ–π —Å–µ—Ç–∫–µ."""
    alpha_min, alpha_max = STUDY_PARAMS["alpha_range"]
    alpha_fine = np.linspace(alpha_min, alpha_max, GRID_POINTS_FINE)
    H_fine = poly(alpha_fine)
    dH = np.gradient(H_fine, alpha_fine)
    d2H = np.gradient(dH, alpha_fine)
    return alpha_fine, dH, d2H


def analyze_model(model: dict[str, Any], alpha_data: np.ndarray, H_data: np.ndarray) -> dict[str, Any]:
    """–ü—Ä–æ–≤–æ–¥–∏—Ç –ø–æ–ª–Ω—ã–π –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –º–æ–¥–µ–ª–∏."""
    poly = model["poly"]
    alpha_min, alpha_max = STUDY_PARAMS["alpha_range"]
    our_alpha = OUR_UNIVERSE["alpha"]

    # –ü–∏–∫ –º–æ–¥–µ–ª–∏
    result = minimize_scalar(
        lambda x: -poly(x),
        bounds=PEAK_SEARCH_BOUNDS,
        method="bounded",
    )
    peak_alpha, peak_H = result.x, poly(result.x)
    our_H = poly(our_alpha)

    # –ü—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ
    alpha_fine, dH, d2H = _compute_derivatives(poly)
    peak_idx = np.argmin(np.abs(alpha_fine - peak_alpha))
    our_idx = np.argmin(np.abs(alpha_fine - our_alpha))

    # –ì—Ä–∞–Ω–∏—Ü—ã –∑–æ–Ω
    boundaries = {
        "left_optimal": _find_boundary(poly, THRESHOLDS["optimal"], peak_alpha, "left"),
        "right_optimal": _find_boundary(poly, THRESHOLDS["optimal"], peak_alpha, "right"),
        "right_marginal": _find_boundary(poly, THRESHOLDS["marginal"], peak_alpha, "right"),
    }

    # –ò–Ω—Ç–µ–≥—Ä–∞–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
    total_area, _ = quad(poly, alpha_min, alpha_max)
    mean_H = total_area / (alpha_max - alpha_min)
    relative_advantage = (our_H / mean_H - 1) * 100

    # –ì—Ä–∞–Ω–∏—Ü–∞ hostile
    alpha_hostile = float(fsolve(lambda x: poly(x) - THRESHOLDS["hostile"], 0.011)[0])

    return {
        "peak": {"alpha": peak_alpha, "H": peak_H},
        "our": {
            "alpha": our_alpha,
            "H": our_H,
            "deviation": our_H - peak_H,
        },
        "derivatives": {
            "dH_peak": dH[peak_idx],
            "dH_our": dH[our_idx],
            "d2H_peak": d2H[peak_idx],
            "d2H_our": d2H[our_idx],
            "slope_per_0_001": dH[our_idx] * 0.001,
        },
        "boundaries": boundaries,
        "integral": {
            "mean_H": mean_H,
            "relative_advantage": relative_advantage,
            "total_area": total_area,
        },
        "hostile_boundary": alpha_hostile,
    }

# ============================================================================
# 5. –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –ò –û–¢–ß–ï–¢–´
# ============================================================================


def _get_timestamp() -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â—É—é –º–µ—Ç–∫—É –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤."""
    return datetime.now().strftime("%Y%m%d_%H%M%S")


def _format_analysis_report(model: dict[str, Any], analysis: dict[str, Any]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –∞–Ω–∞–ª–∏–∑–∞."""
    b = analysis["boundaries"]
    left_opt = f"{b['left_optimal']:.4f}" if b["left_optimal"] is not None else "N/A"
    right_opt = f"{b['right_optimal']:.4f}" if b["right_optimal"] is not None else "N/A"
    right_marg = f"{b['right_marginal']:.4f}" if b["right_marginal"] is not None else "N/A"
    return f"""
    üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê
    =====================

    üìê –ú–û–î–ï–õ–¨:
    {model['expression']}
    R¬≤ = {model['r_squared']:.6f}

    üéØ –ü–ò–ö:
    Œ±_peak = {analysis['peak']['alpha']:.6f}
    H_peak = {analysis['peak']['H']:.6f}

    üåç –ù–ê–®–ê –í–°–ï–õ–ï–ù–ù–ê–Ø:
    Œ± = {analysis['our']['alpha']:.6f}
    H = {analysis['our']['H']:.6f}
    ŒîH = {analysis['our']['deviation']:+.6f}

    üìà –ü–†–û–ò–ó–í–û–î–ù–´–ï:
    dH/dŒ± —É –Ω–∞—Å = {analysis['derivatives']['dH_our']:.2f}
    –ü—Ä–∏ ŒîŒ±=0.001 ‚Üí ŒîH={analysis['derivatives']['slope_per_0_001']:.6f}

    üìè –ì–†–ê–ù–ò–¶–´:
    OPTIMAL: [{left_opt}, {right_opt}]
    MARGINAL –¥–æ: {right_marg}
    HOSTILE –ø—Ä–∏ Œ± > {analysis['hostile_boundary']:.4f}

    üìä –ò–ù–¢–ï–ì–†–ê–õ:
    –°—Ä–µ–¥–Ω–∏–π H = {analysis['integral']['mean_H']:.4f}
    –ú—ã –≤—ã—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –Ω–∞ {analysis['integral']['relative_advantage']:.2f}%
    """


def _plot_main_chart(ax: plt.Axes, data: dict, model: dict, analysis: dict) -> None:
    """–†–∏—Å—É–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –≥—Ä–∞—Ñ–∏–∫ —Å –¥–∞–Ω–Ω—ã–º–∏, –º–æ–¥–µ–ª—å—é –∏ –∑–æ–Ω–∞–º–∏."""
    alpha_min, alpha_max = STUDY_PARAMS["alpha_range"]
    alpha_fine = np.linspace(alpha_min, alpha_max, GRID_POINTS_PLOT)
    H_fine = model["poly"](alpha_fine)
    b = analysis["boundaries"]
    right_opt = b["right_optimal"] or alpha_max
    right_marg = b["right_marginal"] or alpha_max

    if b["left_optimal"] is not None and b["right_optimal"] is not None:
        ax.axvspan(b["left_optimal"], b["right_optimal"], alpha=0.2, color="green", label="OPTIMAL –∑–æ–Ω–∞")
    ax.axvspan(right_opt, right_marg, alpha=0.2, color="yellow", label="MARGINAL –∑–æ–Ω–∞")
    ax.axvspan(right_marg, alpha_max, alpha=0.2, color="red", label="HOSTILE –∑–æ–Ω–∞")

    ax.plot(data["alpha"], data["H"], "bo", markersize=6, label="–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ —Ç–æ—á–∫–∏", alpha=0.6)
    ax.plot(alpha_fine, H_fine, "b-", linewidth=2, label=f"–ú–æ–¥–µ–ª—å (R¬≤={model['r_squared']:.4f})")
    ax.plot(analysis["peak"]["alpha"], analysis["peak"]["H"], "g*", markersize=20, label="–ü–∏–∫ –º–æ–¥–µ–ª–∏")
    ax.plot(analysis["our"]["alpha"], analysis["our"]["H"], "r*", markersize=20, label="–ù–∞—à–∞ –í—Å–µ–ª–µ–Ω–Ω–∞—è")

    for zone, thresh in THRESHOLDS.items():
        ax.axhline(y=thresh, color=ZONE_COLORS[zone], linestyle="--", alpha=0.5)

    ax.set_xlabel("Œ±", fontsize=12)
    ax.set_ylabel("–ò–Ω–¥–µ–∫—Å –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç–∏ H", fontsize=12)
    ax.set_title("–î–∞–Ω–Ω—ã–µ –∏ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å", fontsize=14)
    ax.legend(loc="best", fontsize=8)
    ax.grid(True, alpha=0.3)


def create_visualization(data: dict[str, Any], model: dict[str, Any], analysis: dict[str, Any]) -> None:
    """–°–æ–∑–¥–∞–µ—Ç –ø–æ–ª–Ω—É—é –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —Å –¥–∞–Ω–Ω—ã–º–∏ –∏ –º–æ–¥–µ–ª—å—é."""
    plt.style.use("seaborn-v0_8-darkgrid")
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    alpha_min, alpha_max = STUDY_PARAMS["alpha_range"]
    alpha_fine = np.linspace(alpha_min, alpha_max, GRID_POINTS_PLOT)
    H_fine = model["poly"](alpha_fine)

    _plot_main_chart(axes[0, 0], data, model, analysis)

    # –û—Å—Ç–∞—Ç–∫–∏
    ax2 = axes[0, 1]
    residuals = data["H"] - model["poly"](data["alpha"])
    ax2.bar(range(len(residuals)), residuals, color="purple", alpha=0.6)
    ax2.axhline(y=0, color="black", linestyle="-", linewidth=1)
    ax2.set_xlabel("–¢–æ—á–∫–∞ –¥–∞–Ω–Ω—ã—Ö", fontsize=12)
    ax2.set_ylabel("–û—Å—Ç–∞—Ç–∫–∏ (H_data - H_model)", fontsize=12)
    ax2.set_title("–ê–Ω–∞–ª–∏–∑ –æ—Å—Ç–∞—Ç–∫–æ–≤ –º–æ–¥–µ–ª–∏", fontsize=14)
    ax2.grid(True, alpha=0.3)

    # –ü—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ
    ax3 = axes[1, 0]
    dH = np.gradient(H_fine, alpha_fine)
    ax3.plot(alpha_fine, dH, "r-", linewidth=2, label="dH/dŒ±")
    ax3.axvline(x=analysis["our"]["alpha"], color="blue", linestyle="--", label="–ù–∞—à–∞ Œ±", alpha=0.5)
    ax3.axhline(y=0, color="black", linestyle="-", linewidth=1)
    ax3.set_xlabel("Œ±", fontsize=12)
    ax3.set_ylabel("–°–∫–æ—Ä–æ—Å—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è", fontsize=12)
    ax3.set_title("–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è –º–æ–¥–µ–ª–∏", fontsize=14)
    ax3.legend(loc="best")
    ax3.grid(True, alpha=0.3)

    # –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç
    ax4 = axes[1, 1]
    ax4.axis("off")
    ax4.text(
        0.1, 0.95,
        _format_analysis_report(model, analysis),
        fontsize=10,
        fontfamily="monospace",
        verticalalignment="top",
        bbox=dict(boxstyle="round", facecolor="lightyellow"),
    )

    plt.suptitle("–ü–û–õ–ù–´–ô –ê–ù–ê–õ–ò–ó –ü–õ–ê–¢–û –ü–†–ò–ì–û–î–ù–û–°–¢–ò –í–°–ï–õ–ï–ù–ù–´–•", fontsize=16, fontweight="bold", y=1.02)
    plt.tight_layout()

    os.makedirs(OUTPUT_DIR, exist_ok=True)
    filename = f"{OUTPUT_DIR}/full_analysis_{_get_timestamp()}.png"
    plt.savefig(filename, dpi=300, bbox_inches="tight")
    print(f"\nüì∏ –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")
    plt.show()

# ============================================================================
# 6. –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
# ============================================================================


def _analysis_to_serializable(analysis: dict[str, Any]) -> dict[str, Any]:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∞–Ω–∞–ª–∏–∑ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É, –ø—Ä–∏–≥–æ–¥–Ω—É—é –¥–ª—è JSON."""
    boundaries = {
        k: float(v) if v is not None else None
        for k, v in analysis["boundaries"].items()
    }
    return {
        "peak": {k: float(v) for k, v in analysis["peak"].items()},
        "our": {k: float(v) if isinstance(v, (int, float)) else v for k, v in analysis["our"].items()},
        "derivatives": {k: float(v) for k, v in analysis["derivatives"].items()},
        "boundaries": boundaries,
        "integral": {k: float(v) for k, v in analysis["integral"].items()},
        "hostile_boundary": float(analysis["hostile_boundary"]),
    }


def save_results(data: dict[str, Any], model: dict[str, Any], analysis: dict[str, Any]) -> None:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ CSV, JSON –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç."""
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    timestamp = _get_timestamp()
    alpha_min, alpha_max = STUDY_PARAMS["alpha_range"]

    # CSV
    df = pd.DataFrame({"alpha": data["alpha"], "H": data["H"]})
    csv_file = f"{OUTPUT_DIR}/alpha_data_{timestamp}.csv"
    df.to_csv(csv_file, index=False)
    print(f"üìä –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {csv_file}")

    # JSON
    results_dict = {
        "timestamp": timestamp,
        "study_params": STUDY_PARAMS,
        "our_universe": OUR_UNIVERSE,
        "thresholds": THRESHOLDS,
        "model": {
            "coeffs": model["coeffs"].tolist(),
            "degree": model["degree"],
            "r_squared": model["r_squared"],
            "expression": model["expression"],
        },
        "analysis": _analysis_to_serializable(analysis),
    }
    json_file = f"{OUTPUT_DIR}/analysis_{timestamp}.json"
    with open(json_file, "w", encoding="utf-8") as f:
        json.dump(results_dict, f, indent=2, ensure_ascii=False)
    print(f"üìã –ê–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {json_file}")

    # –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç
    txt_file = f"{OUTPUT_DIR}/report_{timestamp}.txt"
    report_body = _format_analysis_report(model, analysis)
    with open(txt_file, "w", encoding="utf-8") as f:
        f.write("=" * 80 + "\n")
        f.write("–û–¢–ß–ï–¢ –û–ë –ò–°–°–õ–ï–î–û–í–ê–ù–ò–ò –ü–õ–ê–¢–û –ü–†–ò–ì–û–î–ù–û–°–¢–ò –í–°–ï–õ–ï–ù–ù–´–•\n")
        f.write("=" * 80 + "\n\n")
        f.write("üìä –î–ê–ù–ù–´–ï:\n")
        f.write(f"   –î–∏–∞–ø–∞–∑–æ–Ω Œ±: [{alpha_min}, {alpha_max}]\n")
        f.write(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫: {len(data['alpha'])}\n\n")
        f.write(report_body)
    print(f"üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {txt_file}")

# ============================================================================
# 7. –û–°–ù–û–í–ù–ê–Ø –ü–†–û–ì–†–ê–ú–ú–ê
# ============================================================================


def main() -> None:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –∞–Ω–∞–ª–∏–∑–∞ –ø–ª–∞—Ç–æ –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç–∏ –≤—Å–µ–ª–µ–Ω–Ω—ã—Ö."""
    print("\n" + "=" * 80)
    print("üöÄ –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê –ü–õ–ê–¢–û –ü–†–ò–ì–û–î–ù–û–°–¢–ò")
    print("=" * 80)

    data = generate_alpha_data()
    model = fit_polynomial(data["alpha"], data["H"], degree=3)
    analysis = analyze_model(model, data["alpha"], data["H"])
    create_visualization(data, model, analysis)
    save_results(data, model, analysis)

    print("\n" + "=" * 80)
    print("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û!")
    print("=" * 80)


if __name__ == "__main__":
    main()
